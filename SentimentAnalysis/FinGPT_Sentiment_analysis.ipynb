{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9470d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T16:09:06.639869600Z",
     "start_time": "2025-04-16T16:09:05.442676300Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r \"../requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe2d997e44548e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T16:11:53.245076700Z",
     "start_time": "2025-04-16T16:10:50.102989500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7d289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo nvidia-smi --gpu-reset -i 0\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c8bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.reset_max_memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622f687f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T16:14:04.253965900Z",
     "start_time": "2025-04-16T16:14:04.245966600Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c549713122b7e2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T16:16:11.203369Z",
     "start_time": "2025-04-16T16:15:29.165695400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install transformers==4.40.1 peft==0.4.0\n",
    "!pip install sentencepiece\n",
    "!pip install accelerate\n",
    "!pip install torch\n",
    "!pip install peft\n",
    "!pip install datasets\n",
    "!pip install bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4363a905e1a52796",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T16:20:21.194994300Z",
     "start_time": "2025-04-16T16:20:19.642803500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pip install dotenv\n",
    "%pip install accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b1ba19465d55af",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# FinGPT Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaf845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22406dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38a7ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "def print_gpu_memory():\n",
    "    allocated = torch.cuda.memory_allocated() / (1024**2)\n",
    "    cached = torch.cuda.memory_reserved() / (1024**2)\n",
    "    print(f\"Allocated: {allocated:.2f} MB\")\n",
    "    print(f\"Cached: {cached:.2f} MB\")\n",
    "\n",
    "# Before clearing the cache\n",
    "print(\"Before clearing cache:\")\n",
    "print_gpu_memory()\n",
    "\n",
    "# Clearing cache\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# After clearing the cache\n",
    "print(\"\\nAfter clearing cache:\")\n",
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e87690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29052f2582e8c22a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T17:12:32.413107100Z",
     "start_time": "2025-04-16T17:12:08.763191500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, AutoModelForCausalLM, LlamaForCausalLM, LlamaTokenizerFast\n",
    "from peft import PeftModel  # 0.5.0\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "load_dotenv(\n",
    "    dotenv_path=\"../.env\"\n",
    ")\n",
    "huggingface_token = os.getenv(\"FINGPT_ACCESS_TOKEN\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True, \n",
    "    llm_int8_threshold=6.0,\n",
    "    llm_int8_has_fp16_weight=True,\n",
    ")\n",
    "\n",
    "# Load Models\n",
    "base_model = \"meta-llama/Meta-Llama-3-8B\" \n",
    "peft_model = \"FinGPT/fingpt-mt_llama3-8b_lora\"\n",
    "tokenizer = LlamaTokenizerFast.from_pretrained(\n",
    "    base_model, \n",
    "    trust_remote_code=True, \n",
    "    token=huggingface_token,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = LlamaForCausalLM.from_pretrained(base_model, trust_remote_code=True, device_map = \"cuda:0\")\n",
    "model = PeftModel.from_pretrained(model, peft_model)\n",
    "model = model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e723233d652ef4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make prompts\n",
    "prompt = [\n",
    "'''Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}\n",
    "Input: FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is aggressively pursuing its growth strategy by increasingly focusing on technologically more demanding HDI printed circuit boards PCBs .\n",
    "Answer: ''',\n",
    "'''Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}\n",
    "Input: According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .\n",
    "Answer: '''\n",
    "]\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "tokens = tokenizer(prompt, return_tensors='pt', padding=True, max_length=512).to(device)\n",
    "res = model.generate(**tokens, max_length=512)\n",
    "res_sentences = [tokenizer.decode(i) for i in res]\n",
    "out_text = [o.split(\"Answer: \")[1] for o in res_sentences]\n",
    "\n",
    "\n",
    "# Show results\n",
    "for sentiment in out_text:\n",
    "    print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da8004eb0c5e61e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
